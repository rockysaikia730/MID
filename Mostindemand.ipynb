{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb792938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69536900",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path='./chromedriver-mac-arm64/chromedriver')\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b95987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged In\n"
     ]
    }
   ],
   "source": [
    "def linkedin_login():\n",
    "    linkedinHomePage = \"https://www.linkedin.com/login\"\n",
    "    driver.get(linkedinHomePage)\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    username = driver.find_element(By.ID,\"username\")\n",
    "    password = driver.find_element(By.ID,\"password\")\n",
    "    \n",
    "    your_username = #enter username\n",
    "    your_password = #enter password\n",
    "    \n",
    "    username.send_keys(your_username)\n",
    "    password.send_keys(your_password)\n",
    "    \n",
    "    login_button = driver.find_element(By.XPATH,\"//button[@type='submit']\")\n",
    "    login_button.click()\n",
    "    print(\"Logged In\")\n",
    "\n",
    "linkedin_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5489f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jobs :  7340\n",
      "Number of Pages :  294\n"
     ]
    }
   ],
   "source": [
    "def job_listings(url):\n",
    "    driver.get(url)\n",
    "    num_of_results = driver.find_elements(By.CLASS_NAME,\"jobs-search-results-list__subtitle\")[0].text  \n",
    "    num_of_results = num_of_results.split()[0]\n",
    "    num_of_results = int(num_of_results.replace(',',''))\n",
    "\n",
    "    number_of_posting_per_page = 25\n",
    "    number_of_pages = num_of_results//number_of_posting_per_page + 1\n",
    "\n",
    "    print(\"Number of Jobs : \",num_of_results)\n",
    "    print(\"Number of Pages : \",number_of_pages)\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/search/?currentJobId=4129461199&geoId=102713980&keywords=data%20analyst&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true\"\n",
    "job_listings(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "108a79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NLP Model - Skill extraction from JD\n",
    "ner_model = spacy.load(r\"data preprocessing/output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6762b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractskills(job_description):\n",
    "    exp = \"\"\n",
    "    doc = ner_model(job_description)\n",
    "    all_skills = set()\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ == \"EXPERIENCE\"):\n",
    "            skill = ent.text.strip().capitalize()\n",
    "            exp = ent.text\n",
    "        elif(ent.label_ == \"SKILLS\" or ent.label_ == \"SOFT-SKILLS\"):\n",
    "            skill = ent.text.strip().capitalize()\n",
    "            all_skills.add(skill)\n",
    "    \n",
    "    return exp,all_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb776ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInfo(table1,table2):\n",
    "    company_name = driver.find_elements(By.CLASS_NAME,\"job-details-jobs-unified-top-card__company-name\")[0].text\n",
    "    profile = driver.find_elements(By.CLASS_NAME,\"job-details-jobs-unified-top-card__job-title\")[0].text\n",
    "    profile = profile.strip().capitalize()\n",
    "    \n",
    "    job_description = driver.find_elements(By.CLASS_NAME,\"jobs-box__html-content\")[0].text\n",
    "    experience,skills = extractskills(job_description)\n",
    "    if(not skills):\n",
    "        return table1,table2\n",
    "\n",
    "    record1 = pd.DataFrame({'Company': company_name,\n",
    "                            'Profile': profile,\n",
    "                            'Experience':experience},\n",
    "                            index=[len(table1)])\n",
    "    table1 = pd.concat([table1, record1], ignore_index=True)\n",
    "\n",
    "    for skill in skills:\n",
    "        record2 = pd.DataFrame({'f_key':len(table1)-1,'Skills':skill},index=[len(table2)])\n",
    "        table2 = pd.concat([table2, record2], ignore_index=True)\n",
    "\n",
    "    return table1,table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_and_create_table(num_pages = 9):\n",
    "    table1 = pd.DataFrame(columns=[\"Company\",\"Profile\",\"Experience\"])\n",
    "    table2 = pd.DataFrame(columns=[\"f_key\",\"Skills\"])\n",
    "\n",
    "    if(num_pages > 9):\n",
    "        num_pages1 = 9\n",
    "        num_pages2 = num_pages - 9\n",
    "    else:\n",
    "        num_pages1 = num_pages\n",
    "        num_pages2 = 0\n",
    "\n",
    "    for i in range(num_pages1):\n",
    "        #page-flip\n",
    "        driver.find_elements(By.CLASS_NAME,\"artdeco-pagination__indicator--number\")[i].click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        #Select All Job Description\n",
    "        all_job_list = driver.find_elements(By.CLASS_NAME,\"job-card-list__entity-lockup\")\n",
    "\n",
    "        #Extract Info\n",
    "        for j in range(len(all_job_list)):\n",
    "            all_job_list[j].click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            table1,table2 = extractInfo(table1,table2)\n",
    "\n",
    "    for _ in range(9,num_pages2):\n",
    "        driver.find_elements(By.CLASS_NAME,\"artdeco-pagination__indicator--number\")[-4].click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        #Select All Job Description\n",
    "        all_job_list = driver.find_elements(By.CLASS_NAME,\"job-card-list__entity-lockup\")\n",
    "\n",
    "        #Extract Info\n",
    "        for j in range(len(all_job_list)):\n",
    "            all_job_list[j].click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            table1,table2 = extractInfo(table1,table2)\n",
    "\n",
    "    table1 = table1[\"Experience\"].apply(lambda text: int(min([int(i) for i in re.findall(r'\\d+', text)])) if text else 0)\n",
    "    \n",
    "    return table1,table2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c832fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1,table2 = scrap_and_create_table(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def MapToProfile(table1,job_profiles):\n",
    "    n_clusters = len(job_profiles)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform([profile for profile in table1[\"Profile\"]])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X_train)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    #Random selection of few  same label and map to the following list\n",
    "    dic = {}\n",
    "    for label_id in range(n_clusters):\n",
    "        record_labels = np.where(labels == label_id)[0]\n",
    "        sampling_size = 10\n",
    "        record_labels = record_labels[np.random.choice(len(record_labels),sampling_size)]\n",
    "\n",
    "        voting = []\n",
    "        for string1 in table1[\"Profile\"].iloc[record_labels]:\n",
    "            voting1 = [fuzz.ratio(string1, string2) for string2 in job_profiles]\n",
    "            voting.append(np.argmax(voting1))\n",
    "        \n",
    "        mappedKeyword_idx = int(stats.mode(voting)[0])\n",
    "        dic[label_id] = mappedKeyword_idx\n",
    "    \n",
    "    #Add new Column to table1\n",
    "    filtered_names = []\n",
    "    for label in labels:\n",
    "        filtered_names.append(job_profiles[dic[label]])\n",
    "    \n",
    "    table1[\"Filtered_Profile\"] = filtered_names\n",
    "    return table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ac2b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 0, 2: 2}\n"
     ]
    }
   ],
   "source": [
    "job_profiles = [\"Data scientist\",\"Data analyst\",\"Business analyst\"]\n",
    "\n",
    "table1 = MapToProfile(table1,job_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Company.xlsx') as writer:  \n",
    "    table1.to_excel(writer, sheet_name='Company')\n",
    "    table2.to_excel(writer, sheet_name='Skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ba8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "cnx = sqlite3.connect('Company.db')\n",
    "\n",
    "#df1 = pd.read_sql_query(\"SELECT * FROM Company\", cnx)\n",
    "#df2 = pd.read_sql_query(\"SELECT * FROM Skills\", cnx)\n",
    "\n",
    "with pd.ExcelWriter('Company.xlsx') as writer:  \n",
    "    df1.to_excel(writer, sheet_name='Company')\n",
    "    df2.to_excel(writer, sheet_name='Skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da464d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Experience\"] = df1[\"Experience\"].apply(lambda text: int(min([int(i) for i in re.findall(r'\\d+', text)])) if text else 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8527dd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Company</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Filtered_Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Third Bridge Creative</td>\n",
       "      <td>Music data evaluator (india)</td>\n",
       "      <td>2</td>\n",
       "      <td>Data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OptimSpace</td>\n",
       "      <td>Data scientist intern</td>\n",
       "      <td>0</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TwiLearn</td>\n",
       "      <td>Data scientist intern</td>\n",
       "      <td>0</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Data science internship opportunities: second-...</td>\n",
       "      <td>0</td>\n",
       "      <td>Data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Peroptyx</td>\n",
       "      <td>Data analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Data analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Company  \\\n",
       "0      0  Third Bridge Creative   \n",
       "1      1             OptimSpace   \n",
       "2      2               TwiLearn   \n",
       "3      3              Microsoft   \n",
       "4      4               Peroptyx   \n",
       "\n",
       "                                             Profile  Experience  \\\n",
       "0                       Music data evaluator (india)           2   \n",
       "1                              Data scientist intern           0   \n",
       "2                              Data scientist intern           0   \n",
       "3  Data science internship opportunities: second-...           0   \n",
       "4                                       Data analyst           0   \n",
       "\n",
       "  Filtered_Profile  \n",
       "0     Data analyst  \n",
       "1   Data scientist  \n",
       "2   Data scientist  \n",
       "3     Data analyst  \n",
       "4     Data analyst  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8013d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
